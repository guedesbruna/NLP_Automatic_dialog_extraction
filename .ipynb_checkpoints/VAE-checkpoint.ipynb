{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46aea06d",
   "metadata": {},
   "source": [
    "From paper:\n",
    "https://github.com/maitreyeeT/Seq2SeqDialStruct/blob/431419204a4156d633d0d744657fc0cbeef08ce6/Seq2SeqVAE_dialogueStructuring/vae_LSTM.py#L39\n",
    "\n",
    "Look for tutorials on VAE. preferably pytorch? (or not, i don't think i used it yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ec972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# from Seq2SeqVAE_dialogueStructuring.variational_layer import VariationalLayer\n",
    "l = keras.layers\n",
    "m = keras.models\n",
    "K = keras.backend\n",
    "opt = keras.optimizers\n",
    "losses = keras.losses\n",
    "cbk = keras.callbacks\n",
    "reg = keras.regularizers\n",
    "\n",
    "\n",
    "class LSTMVAutoencoder:\n",
    "\n",
    "    def __init__(self, lr, window_size, sequence_size, dropout=0.):\n",
    "        self.lr = lr\n",
    "        self.window_size = window_size\n",
    "        self.sequences_length = sequence_size\n",
    "       # self.input_convolution_size = 3\n",
    "       # self.conv_2d_filters = []  # Num filter of the convolution layers\n",
    "       # self.conv_2d_kernels = []  # Kernel sizes of the convolution layers\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.regul = 1e-4\n",
    "        self.latent_dim = 256\n",
    "        self.build()\n",
    "\n",
    "    def get_attention(self,name, output_size, dropout=0., axis=-2):\n",
    "        model_att = m.Sequential(name='attention_' + str(name))  # (?, n, k, x)\n",
    "        model_att.add(l.Dense(1, activation=K.exp))  # (?, n, k, 1)\n",
    "        model_att.add(l.Lambda(lambda x: x / (K.sum(x, axis=axis, keepdims=True) + \\\n",
    "                                              K.epsilon()),\n",
    "                               name=name + 'attention'))  # (?, n, k, 1)\n",
    "\n",
    "        m_att = m.Sequential()\n",
    "        m_att.add(l.Lambda(lambda x: K.sum(x * model_att(x), axis=axis)))\n",
    "        m_att.add(l.Dense(output_size, activation='linear'))\n",
    "        return m_att\n",
    "\n",
    "    def make_networks(self):\n",
    "        attention = self.get_attention('xylo',10)\n",
    "        #from w2vec_utils import train_word2vec, data_transform\n",
    "        #data_embed = data_transform()\n",
    "        #w2vmodel, embed_wts = train_word2vec(data_embed)\n",
    "        encoder = m.Sequential(name='encoder')\n",
    "        #encoder.add(l.Embedding(output_dim=300, weights=[embed_wts],input_dim=embed_wts.shape[0],\n",
    "        #                        input_shape=(self.sequences_length,2)))\n",
    "        #encoder.add(l.Lambda(lambda x: K.mean(x, axis=-2)))\n",
    "        encoder.add(l.LSTM(10, return_sequences='True'))\n",
    "        encoder.add(l.LSTM(10, return_sequences='True'))\n",
    "\n",
    "        encoder.add(attention)\n",
    "        #encoder.add(l.Dense(5, activity_regularizer=reg.l2(1e-3)))\n",
    "\n",
    "        self.encoder = encoder\n",
    "\n",
    "        decoder = m.Sequential(name='decoder')\n",
    "        decoder.add(l.RepeatVector(self.sequences_length))\n",
    "        decoder.add(l.LSTM(10, return_sequences=True))\n",
    "        decoder.add(l.LSTM(self.window_size, activation='sigmoid'\n",
    "                           , return_sequences=True))\n",
    "\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def build(self):\n",
    "\n",
    "        seq_input = l.Input(shape=(self.sequences_length, self.window_size),\n",
    "                            dtype='float32')  # (?, n, k)\n",
    "\n",
    "        self.make_networks()\n",
    "\n",
    "        latent_in = self.encoder(seq_input)\n",
    "    #     latent_in = VariationalLayer(10, kl_gain=1e-3)(latent_in) <<<< variational layer. commented since i don't yet hve the code for this\n",
    "\n",
    "        decoder_out = self.decoder(latent_in)\n",
    "\n",
    "        model = m.Model(inputs=[seq_input], outputs=[decoder_out])\n",
    "\n",
    "        model_latent = m.Model(inputs=[seq_input], outputs=[latent_in])\n",
    "\n",
    "        model.compile(opt.Adam(self.lr), loss=[lambda x, y: losses.binary_crossentropy(x, y)])\n",
    "\n",
    "        model_latent.compile(opt.RMSprop(1e-3), loss='binary_crossentropy')\n",
    "        self.model = model\n",
    "        self.model_latent = model_latent\n",
    "\n",
    "    def fit(self, X, epochs, callbacks=None, verbose=2):\n",
    "\n",
    "        self.model.fit(x=[X],\n",
    "                       y=[X],\n",
    "                       batch_size=30,\n",
    "                       epochs=epochs,\n",
    "                       validation_split=.2,\n",
    "                       callbacks=callbacks,\n",
    "                       verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45734d9d",
   "metadata": {},
   "source": [
    "### DL class project on VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e304c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from DL class, project 4\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torchvision\n",
    "# import matplotlib.pyplot as plt\n",
    "# from time import time\n",
    "# import os\n",
    "# from torchvision import datasets, transforms\n",
    "# from torch import optim, nn, unsqueeze\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import torch.nn.functional as F\n",
    "# import torchvision.utils as vutils\n",
    "# import torch.nn as nn\n",
    "# from torch.distributions.log_normal import LogNormal\n",
    "# from torchvision.utils import save_image\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# class VAE(nn.Module):\n",
    "#     def __init__(self, D, M):\n",
    "#         super(VAE, self).__init__()\n",
    "#         self.D = D\n",
    "#         self.M = M\n",
    "\n",
    "#         self.enc1 = nn.Linear(in_features=self.D, out_features=300)\n",
    "#         self.enc2 = nn.Linear(in_features=300, out_features=self.M*2)\n",
    "\n",
    "#         self.dec1 = nn.Linear(in_features=self.M, out_features=300)\n",
    "#         self.dec2 = nn.Linear(in_features=300, out_features=self.D)\n",
    "\n",
    "#     def reparameterize(self, mu, log_std): \n",
    "#         std = torch.exp(log_std)\n",
    "#         eps = torch.randn_like(std)\n",
    "#         z = mu + (eps * std)\n",
    "#         return z\n",
    "\n",
    "#     def forward(self, x): \n",
    "#         # encoder\n",
    "#         x = self.enc1(x)\n",
    "#         x = nn.functional.relu(x)\n",
    "#         x = self.enc2(x).view(-1, 2, self.M)\n",
    "        \n",
    "#         # get mean and log-std\n",
    "#         mu = x[:, 0, :]\n",
    "#         log_std = x[:, 1, :]\n",
    "        \n",
    "#         # reparameterization\n",
    "#         z = self.reparameterize(mu, log_std)\n",
    "\n",
    "#         # decoder\n",
    "#         x_hat = nn.functional.relu(self.dec1(z))\n",
    "#         x_hat = torch.sigmoid(self.dec2(x_hat))\n",
    "#         return x_hat, mu, z, log_std\n",
    "\n",
    "#     def generate(self, z):\n",
    "#         x_hat = nn.functional.relu(self.dec1(z))\n",
    "#         x_hat = torch.sigmoid(self.dec2(x_hat))\n",
    "#         return x_hat\n",
    "\n",
    "#     def elbo(self, x, x_hat, z, mu, log_std): \n",
    "#         # reconstruction error\n",
    "#         # RE = nn.loss.mse(x, x_hat)\n",
    "\n",
    "#         RE = F.binary_cross_entropy(x_hat, x)\n",
    "\n",
    "#         # kl-regularization\n",
    "#         # We assume here that log_normal is implemented\n",
    "#         # KL = LogNormal(z, mu, log_std) - LogNormal(z, 0, 1)\n",
    "\n",
    "#         KL = -0.5 * torch.sum(1 + log_std - mu.pow(2) - log_std.exp())\n",
    "#         KL /= (784 * x_hat.size(0))\n",
    "\n",
    "#         # REMEMBER! We maximize ELBO, but optimizers minimize. # Therefore, we need to take the negative sign!\n",
    "#         return -(RE - KL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2d3d4d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(model, dataloader, optimizer):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "\n",
    "#     for i, data in enumerate(dataloader):\n",
    "\n",
    "#         data = data[0].to(device)\n",
    "#         data = data.view(data.size(0),-1)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         data_hat, mu,z, log_std = model(data)\n",
    "#         loss = model.elbo(x = data, x_hat = data_hat,z=z, mu = mu, log_std = log_std)\n",
    "#         running_loss += loss.item()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     train_loss = running_loss/len(dataloader.dataset)\n",
    "#     return train_loss\n",
    "\n",
    "# def validate(model, valdataloader, epoch):\n",
    "#     model.eval()\n",
    "#     running_loss = 0.0\n",
    "#     with torch.no_grad():\n",
    "#         for i, data in enumerate(valdataloader):\n",
    "#             #data, _ = data\n",
    "#             data = data[0].to(device)\n",
    "#             data = data.view(data.size(0),-1)\n",
    "#             data_hat, mu, z, log_std = model(data)\n",
    "#             loss = model.elbo(data, data_hat,z, mu, log_std)\n",
    "#             running_loss += loss.item()\n",
    "\n",
    "#             if (epoch%10 == 0) and (i == len(valiloader)-1):\n",
    "#                 # save the last 8 samples input and output of every 10th epoch\n",
    "#                 num_rows = 8\n",
    "#                 both = torch.cat((data.view(len(data), 1, 28, 28)[:8], \n",
    "#                                   data_hat.view(len(data), 1, 28, 28)[:8]))\n",
    "\n",
    "#                 torchvision.utils.save_image(both.cpu(), f\"./output{epoch}.png\", nrow=num_rows)\n",
    "    \n",
    "#     #val_loss = running_loss/len(valiloader.dataset)\n",
    "#     return running_loss/len(valiloader.dataset)\n",
    "\n",
    "# def train(model, trainloader, valiloader, optimizer, epochs):\n",
    "#     train_loss, val_loss = [], []\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         print(f\"Epoch {epoch+1} of {epochs}\")\n",
    "#         train_epoch_loss = fit(model, trainloader, optimizer)\n",
    "#         val_epoch_loss = validate(model, valiloader, epoch)\n",
    "#         train_loss.append(train_epoch_loss)\n",
    "#         val_loss.append(val_epoch_loss)\n",
    "#         print(f\"Train Loss: {train_epoch_loss:.4f}\")\n",
    "#         print(f\"Val Loss: {val_epoch_loss:.4f}\")\n",
    "\n",
    "#         return model, train_loss, val_loss\n",
    "\n",
    "# BATCH_SIZE = 64\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))]) \n",
    "# # transform = transforms.Compose([transforms.Resize((32, 32)), \n",
    "# #                                 transforms.ToTensor(),\n",
    "# #                                 transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
    "# #                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# #load in full train set\n",
    "# trainsetfull = torchvision.datasets.MNIST(root='./data/mnist', train=True, download=True, transform=transform)\n",
    "# # type(trainsetfull)\n",
    "\n",
    "# # data loader for final run \n",
    "# trainfullloader = torch.utils.data.DataLoader(trainsetfull, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "# #split the set \n",
    "# trainset, valset = torch.utils.data.random_split(trainsetfull, [55000, 5000])\n",
    "# #load in test set\n",
    "# testset = torchvision.datasets.MNIST(root='./data/mnist', train=False, transform=transform,download=True)\n",
    "\n",
    "\n",
    "# # data loader for training\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,shuffle=True, num_workers=2)\n",
    "# # data loader for validation\n",
    "# valiloader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE,shuffle=True, num_workers=2)\n",
    "# # data loader for testing\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,shuffle=False, num_workers=2)\n",
    "\n",
    "# #MNIST\n",
    "# net = VAE(D = 28*28*1, M = 16)\n",
    "# # net = VAE(D = 32*32*3, M = 16)\n",
    "# net.to(device)\n",
    "# optimizer = optim.Adam(net.parameters(), lr = 0.005)\n",
    "# net, train_loss, val_loss= train(net, trainloader, valiloader, optimizer, 50 )\n",
    "\n",
    "#values to plot\n",
    "# val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2c202",
   "metadata": {},
   "source": [
    "## One hot vector of DAs from whole dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "33add13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import pandas as pd\n",
    "from ngrams import add_special_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "79aecd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data_TM2/processed/processed_utterances_sentence_DA_labeling.csv', index_col=0)\n",
    "\n",
    "df, full_DA, unique_ids = add_special_tok(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d2af291d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12719\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "import pickle\n",
    "\n",
    "unique = list(df['all_DA'].unique())\n",
    "one_hot_ubtf = []\n",
    "\n",
    "#uni\n",
    "[one_hot_ubtf.append([x]) for x in unique]\n",
    "\n",
    "#bi\n",
    "for i in range(len(unique)):\n",
    "    for j in range(len(unique)):\n",
    "        one_hot_ubtf.append([unique[i], unique[j]])\n",
    "        \n",
    "#tri >>>>>> until here 12,719\n",
    "for i in range(len(unique)):\n",
    "    for j in range(len(unique)):\n",
    "        for k in range(len(unique)):\n",
    "            one_hot_ubtf.append([unique[i], unique[j], unique[k]])\n",
    "            \n",
    "print(len(one_hot_ubtf))\n",
    "one_hot_ubtf\n",
    "\n",
    "#################\n",
    "\n",
    "dict_grams = {}\n",
    "\n",
    "for e, pat in enumerate(full_DA):\n",
    "    pat = (' ').join(pat)\n",
    "\n",
    "    for uni in ngrams(pat.split(), 1):\n",
    "        uni = list(uni)\n",
    "        if pat not in dict_grams:\n",
    "            dict_grams[pat] = [uni]\n",
    "        else:\n",
    "            dict_grams[pat].extend([uni])\n",
    "\n",
    "    for bi in ngrams(pat.split(), 2):\n",
    "        bi = list(bi)\n",
    "        if pat not in dict_grams:\n",
    "            dict_grams[pat] = [bi]\n",
    "        dict_grams[pat].extend([bi])\n",
    "\n",
    "    for tri in ngrams(pat.split(), 3):\n",
    "        tri = list(tri)\n",
    "        if pat not in dict_grams:\n",
    "            dict_grams[pat] = [tri]\n",
    "        dict_grams[pat].extend([tri])\n",
    "\n",
    "dict_grams\n",
    "\n",
    "with open('./src/generated_files/dict_all_possible_grams.pkl', 'wb') as fp:\n",
    "    pickle.dump(one_hot_ubtf, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "685114f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# create matrix size len(one_hot_ubtf) X len(hmm_results). TO GET FULL SIZE MATRIX:\n",
    "# one_hot_mat = np.zeros((len(dict_grams.keys()), len(one_hot_ubtf))) #format: mat_one_hot[row=dict_grams.keys][column_one_hot]\n",
    "\n",
    "\n",
    "# create matrix size len(one_hot_ubtf) X len(hmm_results). TO GET SAMPLE:\n",
    "one_hot_mat = np.zeros((100, len(one_hot_ubtf))) #format: mat_one_hot[row=dict_grams.keys][column_one_hot]\n",
    "\n",
    "dict_grams_sample = dict(itertools.islice(dict_grams.items(), 100))\n",
    "# print(dict_grams_sample)\n",
    "\n",
    "for e, pattern in enumerate(dict_grams_sample.values()):\n",
    "    for g, pat in enumerate(pattern):\n",
    "        for f, pos_ngr in enumerate(one_hot_ubtf):\n",
    "            if pos_ngr == pat:\n",
    "                one_hot_mat[e][f] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "81458bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12719"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_hot_mat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374550eb",
   "metadata": {},
   "source": [
    "## LSTM Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6edecb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), name='lstm_213/strided_slice_3:0', description=\"created by layer 'lstm_213'\")\n",
      "[array([[[ 0.2881454 ],\n",
      "        [ 0.8721983 ],\n",
      "        [ 1.8641942 ],\n",
      "        [ 3.1861396 ],\n",
      "        [ 3.9022322 ],\n",
      "        [-0.01377723]]], dtype=float32), array([[[ 0.9651851 ],\n",
      "        [ 1.9545611 ],\n",
      "        [ 3.0658395 ],\n",
      "        [ 3.9779654 ],\n",
      "        [-0.00785341]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#only AE with LSTM. from here https://machinelearningmastery.com/lstm-autoencoders/\n",
    "\n",
    "# lstm autoencoder reconstruct and predict sequence\n",
    "from numpy import array\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "# define input sequence\n",
    "seq_in = array([0,1,2,3,4,0]) # seq of DAs \n",
    "# reshape input into [samples, timesteps, features]\n",
    "n_in = len(seq_in)\n",
    "seq_in = seq_in.reshape((1, n_in, 1))\n",
    "# prepare output sequence\n",
    "seq_out = seq_in[:, 1:, :]\n",
    "n_out = n_in - 1\n",
    "\n",
    "# define encoder\n",
    "visible = Input(shape=(n_in,1))\n",
    "encoder = LSTM(10, activation='relu')(visible)\n",
    "print(encoder)\n",
    "\n",
    "# define reconstruct decoder\n",
    "decoder1 = RepeatVector(n_in)(encoder)\n",
    "decoder1 = LSTM(10, activation='relu', return_sequences=True)(decoder1)\n",
    "decoder1 = TimeDistributed(Dense(1))(decoder1)\n",
    "\n",
    "# define predict decoder\n",
    "decoder2 = RepeatVector(n_out)(encoder)\n",
    "decoder2 = LSTM(100, activation='relu', return_sequences=True)(decoder2)\n",
    "decoder2 = TimeDistributed(Dense(1))(decoder2)\n",
    "\n",
    "# tie it together\n",
    "model = Model(inputs=visible, outputs=[decoder1, decoder2])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(seq_in, [seq_in,seq_out], epochs=300, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "yhat = model.predict(seq_in, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c50cc83",
   "metadata": {},
   "source": [
    "## from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "11ffbb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_138 (InputLayer)          [(None, 12719, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_312 (LSTM)                 (None, 12719, 10)    480         input_138[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_313 (LSTM)                 (None, 12719, 10)    840         lstm_312[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_55 (Flatten)            (None, 127190)       0           lstm_313[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_174 (Dense)               (None, 1)            127191      flatten_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            4           dense_174[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            4           dense_174[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sampling_45 (Sampling)          (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 128,519\n",
      "Trainable params: 128,519\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_139 (InputLayer)       [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 127190)            381570    \n",
      "_________________________________________________________________\n",
      "reshape_33 (Reshape)         (None, 12719, 10)         0         \n",
      "_________________________________________________________________\n",
      "lstm_314 (LSTM)              (None, 12719, 10)         840       \n",
      "_________________________________________________________________\n",
      "lstm_315 (LSTM)              (None, 12719, 10)         840       \n",
      "=================================================================\n",
      "Total params: 383,250\n",
      "Trainable params: 383,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# lstm autoencoder reconstruct and predict sequence\n",
    "#https://keras.io/examples/generative/vae/\n",
    "\n",
    "from numpy import array\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Flatten, Layer\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class Sampling(Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "latent_dim = 2\n",
    "\n",
    "n_in = len(one_hot_mat[0])\n",
    "\n",
    "# def encode(n_in = len(one_hot_mat[0])):\n",
    "# define encoder\n",
    "visible = Input(shape=(n_in,1))\n",
    "x = LSTM(10, activation='relu', return_sequences=True)(visible)\n",
    "x = LSTM(10, activation='relu', return_sequences=True)(x) \n",
    "x = Flatten()(x)\n",
    "x = Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "z_mean = Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = Model(visible, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "print(encoder.summary())\n",
    "#     return encoder\n",
    "\n",
    "\n",
    "# def decode(encoder):\n",
    "latent_inputs = Input(shape=(latent_dim,))\n",
    "x = keras.layers.Flatten()(x) \n",
    "x = Dense(10*n_in, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((n_in, 10))(x)\n",
    "x = LSTM(10, activation='relu', return_sequences=True)(x)\n",
    "x = LSTM(10, activation='relu', return_sequences=True)(x) #############\n",
    "decoder = Model(latent_inputs, x, name=\"decoder\")\n",
    "print(decoder.summary())\n",
    "#     return decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3ed16338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the VAE as a Model with a custom train_step\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)))\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {\"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "de1f6314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(100, 12719)\n",
      "(70000, 28, 28, 1)\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /var/folders/3s/9v17gzrj1kvctdbg2vd9d2qw0000gn/T/ipykernel_23854/2530551998.py:23 train_step\n        reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)))\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/keras/losses.py:1809 binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/keras/backend.py:5015 binary_crossentropy\n        bce = target * tf.math.log(output + epsilon())\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n        raise e\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n        return func(x, y, name=name)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1710 _mul_dispatch\n        return multiply(x, y, name=name)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:530 multiply\n        return gen_math_ops.mul(x, y, name)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:6245 mul\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3561 _create_op_internal\n        ret = Operation(\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 12719 and 10 for '{{node mul}} = Mul[T=DT_FLOAT](IteratorGetNext, Log)' with input shapes: [?,12719], [?,12719,10].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3s/9v17gzrj1kvctdbg2vd9d2qw0000gn/T/ipykernel_23854/2172857215.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3298\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/keras/engine/training.py:853 train_function  *\n        return step_function(self, iterator)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/keras/engine/training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/distribute/distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/keras/engine/training.py:835 run_step  **\n        outputs = model.train_step(data)\n    /var/folders/3s/9v17gzrj1kvctdbg2vd9d2qw0000gn/T/ipykernel_23854/2530551998.py:23 train_step\n        reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)))\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/keras/losses.py:1809 binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/keras/backend.py:5015 binary_crossentropy\n        bce = target * tf.math.log(output + epsilon())\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1383 binary_op_wrapper\n        raise e\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1367 binary_op_wrapper\n        return func(x, y, name=name)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:1710 _mul_dispatch\n        return multiply(x, y, name=name)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/ops/math_ops.py:530 multiply\n        return gen_math_ops.mul(x, y, name)\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_math_ops.py:6245 mul\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3561 _create_op_internal\n        ret = Operation(\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /Users/brunaguedes/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 12719 and 10 for '{{node mul}} = Mul[T=DT_FLOAT](IteratorGetNext, Log)' with input shapes: [?,12719], [?,12719,10].\n"
     ]
    }
   ],
   "source": [
    "# Train the VAE\n",
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
    "print(type(mnist_digits))\n",
    "print(type(one_hot_mat))\n",
    "\n",
    "print(one_hot_mat.shape)\n",
    "print(mnist_digits.shape)\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(one_hot_mat, epochs=30, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d99db5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display how the latent space clusters different digit classes\n",
    "def plot_label_clusters(vae, data, labels):\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = vae.encoder.predict(data)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=labels)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.show()\n",
    "\n",
    "(x_train, y_train), _ = keras.datasets.mnist.load_data()\n",
    "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
    "\n",
    "plot_label_clusters(vae, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c729ded",
   "metadata": {},
   "source": [
    "Variational autoencoders are unsupervised learning methods in the sense that they don't require labels in addition to the data inputs. All that is required for VAE is to define an appropriate likelihood function for your data. Commonly, a reconstruction loss is used, e.g. binary cross-entropy, squared distance, or absolute distance, to compare the actual input to the VAE with the generated output of the VAE. If you want to use VAE for dimensionality reduction or feature extraction, you would feed our data to the encoder network and use its output for downstream tasks.\n",
    "\n",
    "Keep in mind that VAE is a generative model, thus training encourages the output of the encoder to resemble an isotropic Gaussian distribution. If you don't need to generate data and just want to extract features, you might get better results with a traditional autoencoder without the Kullback-Leibler divergence regularizer that is used in VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f895c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
