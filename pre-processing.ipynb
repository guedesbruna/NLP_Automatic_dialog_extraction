{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e943a33b",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "\n",
    "## All preprocessing just needs to be done once. \n",
    "### If already done go direclty to DA patterns to load csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de9d64ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.io.json import json_normalize\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sklearn\n",
    "from sklearn.metrics import f1_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ccba6b",
   "metadata": {},
   "source": [
    "#### Open all datasets from different tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e7d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t1 = pd.read_json('./data_TM2/flights.json')\n",
    "df_t2 = pd.read_json('./data_TM2/food-ordering.json')\n",
    "df_t3 = pd.read_json('./data_TM2/hotels.json')\n",
    "df_t4 = pd.read_json('./data_TM2/movies.json')\n",
    "df_t5 = pd.read_json('./data_TM2/music.json')\n",
    "df_t6 = pd.read_json('./data_TM2/restaurant-search.json')\n",
    "df_t7 = pd.read_json('./data_TM2/sports.json')\n",
    "\n",
    "# create extra column in the beginning for type of task before merging\n",
    "df_t1.insert(0, 'task', 'flights')\n",
    "df_t2.insert(0, 'task', 'food-ordering')\n",
    "df_t3.insert(0, 'task', 'hotels')\n",
    "df_t4.insert(0, 'task', 'movies')\n",
    "df_t5.insert(0, 'task', 'music')\n",
    "df_t6.insert(0, 'task', 'restaurant-search')\n",
    "df_t7.insert(0, 'task', 'sports')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7cfaa8",
   "metadata": {},
   "source": [
    "#### Normalize json and change to pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867f1f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw(df): #, name):\n",
    "    dialogs = []\n",
    "\n",
    "    for e,i in enumerate(df['utterances']):\n",
    "        for j in i:\n",
    "            new_df=pd.json_normalize(j)\n",
    "            new_df.insert(0, 'task', df['task'][e])\n",
    "            new_df.insert(1, 'conversation_id', df['conversation_id'][e])\n",
    "            new_df.insert(2, 'instruction_id', df['instruction_id'][e])\n",
    "        \n",
    "            dialogs.append(new_df)\n",
    "\n",
    "    large_df = pd.concat(dialogs, ignore_index=True)\n",
    "#   large_df.to_csv('./data_TM2/processed_utterances_'+name+'.csv')\n",
    "    \n",
    "    return large_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43582db7",
   "metadata": {},
   "source": [
    "#### Create unique dataset with normalized tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607586e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(df_list):\n",
    "    large_frames = []\n",
    "\n",
    "    for df_ in df_list:\n",
    "        large_df = process_raw(df_)\n",
    "        large_frames.append(large_df)\n",
    "\n",
    "    all_tasks = pd.concat(large_frames, ignore_index=True)\n",
    "    all_tasks.to_csv('./data_TM2/concatenated_tasks.csv')\n",
    "    \n",
    "    return all_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03061b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df_t1, df_t2, df_t3, df_t4, df_t5, df_t6, df_t7]\n",
    "all_tasks = unique(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb3bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #essa parte é de antes porem com split incluindo simbolo do split\n",
    "# new_text = []\n",
    "# for ut in df['text']:\n",
    "#     new_ut = re.split('(\\.)', ut)\n",
    "#     new_text.append(new_ut)\n",
    "# df['new_text'] = new_text\n",
    "\n",
    "# #to keep delimiter in sentence\n",
    "# #not very efficient way of doing it, apparently a better way using regex symbols\n",
    "\n",
    "# new_lista = []\n",
    "# for row in df['new_text']:\n",
    "# #     print(row)\n",
    "#     for e, word in enumerate(row):\n",
    "#         if word == '.':\n",
    "#             new_lista.append(row[e-1]+row[e])\n",
    "#             new_lista.remove(row[e-1])\n",
    "#         else:\n",
    "#             new_lista.append(word)\n",
    "\n",
    "# df = df.explode('new_text')\n",
    "# df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3bf22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "df = pd.read_csv('./data_TM2/concatenated_tasks.csv', index_col=0)\n",
    "\n",
    "tokenized = []\n",
    "for ut in df['text']:\n",
    "    tokenized.append(sent_tokenize(ut))\n",
    "    \n",
    "df['new_lista'] = tokenized\n",
    "df = df.explode('new_lista')\n",
    "df = df.reset_index(drop=True)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890e096c",
   "metadata": {},
   "source": [
    "## Sample a part of the dataset to annotate\n",
    "### criteria:\n",
    "\n",
    "- take from all taks\n",
    "- annotate full dialogues\n",
    "- how many dialogues are there? what's the percentage of full dialogues i want to annotate?\n",
    "17304 dialogues (index 0 demarks the begining of a dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db5b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of dialogues:\n",
    "df_count = pd.read_csv('./data_TM2/concatenated_tasks.csv', index_col=0)\n",
    "print(df_count['conversation_id'].nunique())\n",
    "\n",
    "#average size of dialog\n",
    "print(df_count['index'].mean())\n",
    "\n",
    "#dialogues per task (i.e True column)\n",
    "pd.crosstab(df_count['task'], df_count['index'] ==0).sort_values(by='task', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e87bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample randomly 167 dialogues, that will be split into 2 batches:\n",
    "#selection made using the unique conversation_ids\n",
    "\n",
    "np.random.seed(0)\n",
    "unique_conv_id = df['conversation_id'].unique()\n",
    "sample_ids = np.random.choice(unique_conv_id, 172, replace=False)\n",
    "\n",
    "sample_b1  = []\n",
    "sample_b2  = []\n",
    "for e, row in enumerate(df['conversation_id']):\n",
    "    for b1 in sample_ids[:int(len(sample_ids)/2)]:\n",
    "        if row == b1:\n",
    "            sample_b1.append(df.loc[e,:])\n",
    "    for b2 in sample_ids[int(len(sample_ids)/2):]:\n",
    "        if row == b2:\n",
    "            sample_b2.append(df.loc[e,:])\n",
    "\n",
    "df_sample_b1 = pd.DataFrame(sample_b1)\n",
    "df_sample_b2 = pd.DataFrame(sample_b2)\n",
    "\n",
    "df_sample_b1.to_csv('./data_TM2/sample_b1.csv')\n",
    "df_sample_b2.to_csv('./data_TM2/sample_b2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b2f80",
   "metadata": {},
   "source": [
    "## Load gold label dataset to work with DA patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "453fdeb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>instruction_id</th>\n",
       "      <th>index</th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "      <th>segments</th>\n",
       "      <th>new_text</th>\n",
       "      <th>gold_labels</th>\n",
       "      <th>G_DA_rep_init</th>\n",
       "      <th>...</th>\n",
       "      <th>G_DA_receipt</th>\n",
       "      <th>G_DA_disconf</th>\n",
       "      <th>G_DA_closer</th>\n",
       "      <th>G_DA_comp_check</th>\n",
       "      <th>G_DA_hold</th>\n",
       "      <th>G_DA_partial_req</th>\n",
       "      <th>G_DA_detail_req</th>\n",
       "      <th>G_DA_grant</th>\n",
       "      <th>G_DA_answer</th>\n",
       "      <th>gold_formatted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>flights</td>\n",
       "      <td>dlg-07f1ccd9-e109-41c5-8db6-afb4cdd94728</td>\n",
       "      <td>flight-5</td>\n",
       "      <td>0</td>\n",
       "      <td>ASSISTANT</td>\n",
       "      <td>Hello.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hello.</td>\n",
       "      <td>greeting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[greeting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>flights</td>\n",
       "      <td>dlg-07f1ccd9-e109-41c5-8db6-afb4cdd94728</td>\n",
       "      <td>flight-5</td>\n",
       "      <td>1</td>\n",
       "      <td>USER</td>\n",
       "      <td>Hi. I need help organizing a flight. I'm looki...</td>\n",
       "      <td>[{'start_index': 59, 'end_index': 74, 'text': ...</td>\n",
       "      <td>Hi.</td>\n",
       "      <td>greeting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[greeting]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>flights</td>\n",
       "      <td>dlg-07f1ccd9-e109-41c5-8db6-afb4cdd94728</td>\n",
       "      <td>flight-5</td>\n",
       "      <td>1</td>\n",
       "      <td>USER</td>\n",
       "      <td>Hi. I need help organizing a flight. I'm looki...</td>\n",
       "      <td>[{'start_index': 59, 'end_index': 74, 'text': ...</td>\n",
       "      <td>I need help organizing a flight.</td>\n",
       "      <td>partial_request</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>partial_request</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[partial_request]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>flights</td>\n",
       "      <td>dlg-07f1ccd9-e109-41c5-8db6-afb4cdd94728</td>\n",
       "      <td>flight-5</td>\n",
       "      <td>1</td>\n",
       "      <td>USER</td>\n",
       "      <td>Hi. I need help organizing a flight. I'm looki...</td>\n",
       "      <td>[{'start_index': 59, 'end_index': 74, 'text': ...</td>\n",
       "      <td>I'm looking to fly to Dublin, Ireland.</td>\n",
       "      <td>partial_request</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>partial_request</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[partial_request]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>flights</td>\n",
       "      <td>dlg-07f1ccd9-e109-41c5-8db6-afb4cdd94728</td>\n",
       "      <td>flight-5</td>\n",
       "      <td>2</td>\n",
       "      <td>ASSISTANT</td>\n",
       "      <td>Okay. Can you give me some specifications?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>confirmation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[confirmation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436152</th>\n",
       "      <td>sports</td>\n",
       "      <td>dlg-fccb9be2-f9ef-4472-80fb-af3fd0efc78b</td>\n",
       "      <td>mlb-7</td>\n",
       "      <td>10</td>\n",
       "      <td>ASSISTANT</td>\n",
       "      <td>I'm sorry can you repeat the question?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm sorry can you repeat the question?</td>\n",
       "      <td>repair_initiator</td>\n",
       "      <td>repair_initiator</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[repair_initiator]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436153</th>\n",
       "      <td>sports</td>\n",
       "      <td>dlg-fccb9be2-f9ef-4472-80fb-af3fd0efc78b</td>\n",
       "      <td>mlb-7</td>\n",
       "      <td>11</td>\n",
       "      <td>USER</td>\n",
       "      <td>Who's in last place in the American League West?</td>\n",
       "      <td>[{'start_index': 9, 'end_index': 19, 'text': '...</td>\n",
       "      <td>Who's in last place in the American League West?</td>\n",
       "      <td>repair</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[repair]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436154</th>\n",
       "      <td>sports</td>\n",
       "      <td>dlg-fccb9be2-f9ef-4472-80fb-af3fd0efc78b</td>\n",
       "      <td>mlb-7</td>\n",
       "      <td>12</td>\n",
       "      <td>ASSISTANT</td>\n",
       "      <td>The Oakland A's are in last place in the Ameri...</td>\n",
       "      <td>[{'start_index': 4, 'end_index': 13, 'text': '...</td>\n",
       "      <td>The Oakland A's are in last place in the Ameri...</td>\n",
       "      <td>grant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[grant]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436155</th>\n",
       "      <td>sports</td>\n",
       "      <td>dlg-fccb9be2-f9ef-4472-80fb-af3fd0efc78b</td>\n",
       "      <td>mlb-7</td>\n",
       "      <td>13</td>\n",
       "      <td>USER</td>\n",
       "      <td>Awesome. That's all I needed to know, Thank you.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome.</td>\n",
       "      <td>sequence_closer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sequence_closer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[sequence_closer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436156</th>\n",
       "      <td>sports</td>\n",
       "      <td>dlg-fccb9be2-f9ef-4472-80fb-af3fd0efc78b</td>\n",
       "      <td>mlb-7</td>\n",
       "      <td>13</td>\n",
       "      <td>USER</td>\n",
       "      <td>Awesome. That's all I needed to know, Thank you.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>That's all I needed to know, Thank you.</td>\n",
       "      <td>sequence_closer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sequence_closer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[sequence_closer]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2062 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           task                           conversation_id instruction_id  \\\n",
       "2441    flights  dlg-07f1ccd9-e109-41c5-8db6-afb4cdd94728       flight-5   \n",
       "2442    flights  dlg-07f1ccd9-e109-41c5-8db6-afb4cdd94728       flight-5   \n",
       "2443    flights  dlg-07f1ccd9-e109-41c5-8db6-afb4cdd94728       flight-5   \n",
       "2444    flights  dlg-07f1ccd9-e109-41c5-8db6-afb4cdd94728       flight-5   \n",
       "2445    flights  dlg-07f1ccd9-e109-41c5-8db6-afb4cdd94728       flight-5   \n",
       "...         ...                                       ...            ...   \n",
       "436152   sports  dlg-fccb9be2-f9ef-4472-80fb-af3fd0efc78b          mlb-7   \n",
       "436153   sports  dlg-fccb9be2-f9ef-4472-80fb-af3fd0efc78b          mlb-7   \n",
       "436154   sports  dlg-fccb9be2-f9ef-4472-80fb-af3fd0efc78b          mlb-7   \n",
       "436155   sports  dlg-fccb9be2-f9ef-4472-80fb-af3fd0efc78b          mlb-7   \n",
       "436156   sports  dlg-fccb9be2-f9ef-4472-80fb-af3fd0efc78b          mlb-7   \n",
       "\n",
       "        index    speaker                                               text  \\\n",
       "2441        0  ASSISTANT                                             Hello.   \n",
       "2442        1       USER  Hi. I need help organizing a flight. I'm looki...   \n",
       "2443        1       USER  Hi. I need help organizing a flight. I'm looki...   \n",
       "2444        1       USER  Hi. I need help organizing a flight. I'm looki...   \n",
       "2445        2  ASSISTANT         Okay. Can you give me some specifications?   \n",
       "...       ...        ...                                                ...   \n",
       "436152     10  ASSISTANT             I'm sorry can you repeat the question?   \n",
       "436153     11       USER   Who's in last place in the American League West?   \n",
       "436154     12  ASSISTANT  The Oakland A's are in last place in the Ameri...   \n",
       "436155     13       USER   Awesome. That's all I needed to know, Thank you.   \n",
       "436156     13       USER   Awesome. That's all I needed to know, Thank you.   \n",
       "\n",
       "                                                 segments  \\\n",
       "2441                                                  NaN   \n",
       "2442    [{'start_index': 59, 'end_index': 74, 'text': ...   \n",
       "2443    [{'start_index': 59, 'end_index': 74, 'text': ...   \n",
       "2444    [{'start_index': 59, 'end_index': 74, 'text': ...   \n",
       "2445                                                  NaN   \n",
       "...                                                   ...   \n",
       "436152                                                NaN   \n",
       "436153  [{'start_index': 9, 'end_index': 19, 'text': '...   \n",
       "436154  [{'start_index': 4, 'end_index': 13, 'text': '...   \n",
       "436155                                                NaN   \n",
       "436156                                                NaN   \n",
       "\n",
       "                                                 new_text       gold_labels  \\\n",
       "2441                                               Hello.          greeting   \n",
       "2442                                                  Hi.          greeting   \n",
       "2443                     I need help organizing a flight.   partial_request   \n",
       "2444               I'm looking to fly to Dublin, Ireland.   partial_request   \n",
       "2445                                                Okay.      confirmation   \n",
       "...                                                   ...               ...   \n",
       "436152             I'm sorry can you repeat the question?  repair_initiator   \n",
       "436153   Who's in last place in the American League West?            repair   \n",
       "436154  The Oakland A's are in last place in the Ameri...             grant   \n",
       "436155                                           Awesome.   sequence_closer   \n",
       "436156            That's all I needed to know, Thank you.   sequence_closer   \n",
       "\n",
       "           G_DA_rep_init  ... G_DA_receipt G_DA_disconf      G_DA_closer  \\\n",
       "2441                 NaN  ...          NaN          NaN              NaN   \n",
       "2442                 NaN  ...          NaN          NaN              NaN   \n",
       "2443                 NaN  ...          NaN          NaN              NaN   \n",
       "2444                 NaN  ...          NaN          NaN              NaN   \n",
       "2445                 NaN  ...          NaN          NaN              NaN   \n",
       "...                  ...  ...          ...          ...              ...   \n",
       "436152  repair_initiator  ...          NaN          NaN              NaN   \n",
       "436153               NaN  ...          NaN          NaN              NaN   \n",
       "436154               NaN  ...          NaN          NaN              NaN   \n",
       "436155               NaN  ...          NaN          NaN  sequence_closer   \n",
       "436156               NaN  ...          NaN          NaN  sequence_closer   \n",
       "\n",
       "       G_DA_comp_check G_DA_hold G_DA_partial_req G_DA_detail_req G_DA_grant  \\\n",
       "2441               NaN       NaN              NaN             NaN        NaN   \n",
       "2442               NaN       NaN              NaN             NaN        NaN   \n",
       "2443               NaN       NaN  partial_request             NaN        NaN   \n",
       "2444               NaN       NaN  partial_request             NaN        NaN   \n",
       "2445               NaN       NaN              NaN             NaN        NaN   \n",
       "...                ...       ...              ...             ...        ...   \n",
       "436152             NaN       NaN              NaN             NaN        NaN   \n",
       "436153             NaN       NaN              NaN             NaN        NaN   \n",
       "436154             NaN       NaN              NaN             NaN      grant   \n",
       "436155             NaN       NaN              NaN             NaN        NaN   \n",
       "436156             NaN       NaN              NaN             NaN        NaN   \n",
       "\n",
       "       G_DA_answer      gold_formatted  \n",
       "2441           NaN          [greeting]  \n",
       "2442           NaN          [greeting]  \n",
       "2443           NaN   [partial_request]  \n",
       "2444           NaN   [partial_request]  \n",
       "2445           NaN      [confirmation]  \n",
       "...            ...                 ...  \n",
       "436152         NaN  [repair_initiator]  \n",
       "436153         NaN            [repair]  \n",
       "436154         NaN             [grant]  \n",
       "436155         NaN   [sequence_closer]  \n",
       "436156         NaN   [sequence_closer]  \n",
       "\n",
       "[2062 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#format golden label to compare\n",
    "#then process automatic labels using this file\n",
    "\n",
    "df = pd.read_csv('./data_TM2/sample_b1_goldannotated_noAutomaticLabels.csv', index_col=0)\n",
    "# df = df.iloc[:2034]\n",
    "df = df.drop(columns='G_DA_rep')\n",
    "\n",
    "gold = []\n",
    "for label in df['gold_labels']:\n",
    "    gold.append(str(label).split(','))\n",
    "\n",
    "df['gold_formatted'] = gold\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dee0e7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dialogues sampled: 70\n",
      "number of utterances sampled: 2062\n",
      "number of tasks sampled: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['task', 'conversation_id', 'instruction_id', 'index', 'speaker', 'text',\n",
       "       'segments', 'new_text', 'gold_labels', 'G_DA_rep_init', 'G_DA_greet',\n",
       "       'G_DA_req_sum', 'G_DA_conf', 'G_DA_receipt', 'G_DA_disconf',\n",
       "       'G_DA_closer', 'G_DA_comp_check', 'G_DA_hold', 'G_DA_partial_req',\n",
       "       'G_DA_detail_req', 'G_DA_grant', 'G_DA_answer', 'gold_formatted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#about the sample:\n",
    "\n",
    "print('number of dialogues sampled: ' + str(df['conversation_id'].nunique()))\n",
    "print('number of utterances sampled: ' + str(len(df)))\n",
    "print('number of tasks sampled: '+ str(df['task'].nunique()))\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478c38d6",
   "metadata": {},
   "source": [
    "## OR Load whole dataset to work with DA patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635da6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./data_TM2/processed_utterances_all_tasks.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b7d4de",
   "metadata": {},
   "source": [
    "### Find substrings\n",
    "make list of words and rules for labeling DA\n",
    "https://towardsdatascience.com/check-for-a-substring-in-a-pandas-dataframe-column-4b949f64852#:~:text=Using%20%E2%80%9Ccontains%E2%80%9D%20to%20Find%20a,substring%20and%20False%20if%20not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4920aabb",
   "metadata": {},
   "source": [
    "- add new column for subset. since each utterance can only be one thing one column for all DA should be enough. \n",
    "- Later I'll have to check the vocabulary used for generic rules (FS_base_greeting or whatever is)\n",
    "- Also study in the UX book what is repair and other patterns:\n",
    "    - page 243 to 246: NCF pattern language summary\n",
    "\n",
    "Tips:\n",
    "- #NOT_INCLUDE_WORD: \n",
    "    - not_fifa = football_soccer_games.loc[~football_soccer_games['Name'].str.contains('FIFA')]\n",
    "- #to make a new dataframe with slicing subset:\n",
    "    - new_df = df.loc[df['text'].str.contains('|'.join(end_of_request), case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51656f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DA indicators. Obs: the vars bellow are sensitive to spacing !!! 'hi' != ' hi'\n",
    "\n",
    "# greeting = [' hi','hi.','hello','bye'] \n",
    "# repair_initiator = ['sorry','repeat', 'understand', 'mean'] \n",
    "# request_summary = ['correct?','confirm'] #when you ask an information to be confirmed\n",
    "# confirmation = ['yes','correct.','correct ', 'that\\'s it', 'indeed'] #confirmation é a resposta que confirma: ex yes | correct | that's it\n",
    "# sentence_closer = ['awesome','great','perfect','exactly','that\\'s all','that is all', 'thanks', 'thank you', 'pleasure', 'excellent'] \n",
    "# question = ['\\?']\n",
    "# receipt = ['You are welcome', 'you\\'re welcome']\n",
    "# grant = ['got it', 'sure']\n",
    "\n",
    "# ## !!!!! order-sensitive > hierarchical!!!! this variable chooses only one label, rules goes on order. once it assigns one rule it won't check next\n",
    "\n",
    "# temp2=df.new_text.fillna(\"0\")\n",
    "# df['DA_indicators_sent'] =  np.where(temp2.str.contains('|'.join(repair_initiator), case=False), \"repair_initiator\",\n",
    "#                             np.where(temp2.str.contains('|'.join(greeting), case=False), \"greeting\",\n",
    "#                             np.where(temp2.str.contains('|'.join(request_summary), case=False),  \"request_summary\",\n",
    "#                             np.where(temp2.str.contains('|'.join(confirmation), case=False),  \"confirmation\",\n",
    "#                             np.where(temp2.str.contains('|'.join(receipt), case=False),  \"receipt\",\n",
    "#                             np.where(temp2.str.contains('|'.join(grant), case=False),  \"grant\",\n",
    "#                             np.where(temp2.str.contains('|'.join(question), case=False),  \"question\",\n",
    "#                             np.where(temp2.str.contains('|'.join(sentence_closer), case=False), \"sentence_closer\", \"x\"))))))))\n",
    "\n",
    "# df['DA_indicators_sent'].value_counts()\n",
    "\n",
    "# #it works! #binary variables and in the end gather in one new column\n",
    "\n",
    "# df['DA_rep'] =  np.where(temp2.str.contains('|'.join(repair_initiator), case=False), \"repair_initiator\", '')\n",
    "# df['DA_greet'] =  np.where(temp2.str.contains('|'.join(greeting), case=False), \"greeting\", '')\n",
    "# df['DA_req_sum'] =  np.where(temp2.str.contains('|'.join(request_summary), case=False), \"request_summary\", '')\n",
    "# df['DA_conf'] =  np.where(temp2.str.contains('|'.join(confirmation), case=False), \"confirmation\", '')\n",
    "# df['DA_receipt'] =  np.where(temp2.str.contains('|'.join(receipt), case=False), \"receipt\", '')\n",
    "# df['DA_grant'] =  np.where(temp2.str.contains('|'.join(grant), case=False), \"grant\", '')\n",
    "# df['DA_quest'] =  np.where(temp2.str.contains('|'.join(question), case=False), \"question\", '')\n",
    "# df['DA_closer'] =  np.where(temp2.str.contains('|'.join(sentence_closer), case=False), \"sentence_closer\", '')\n",
    "# df['all_DA'] = df[['DA_rep', 'DA_greet','DA_req_sum', 'DA_conf', 'DA_receipt', 'DA_grant', 'DA_quest', 'DA_closer']].agg(' '.join, axis=1)\n",
    "\n",
    "# df['all_DA'] = [word_tokenize(da) for da in df['all_DA']]\n",
    "\n",
    "# # df.loc[:, ['speaker', 'new_text', 'all_DA']].to_csv('analysis_multiple_DA_cases.csv')\n",
    "# df.loc[:, ['speaker', 'new_text', 'all_DA']]\n",
    "# counts = df['all_DA'].value_counts()\n",
    "\n",
    "# # counts.to_csv('count_overlaping_DAs.csv')\n",
    "# data = {'counts':counts}\n",
    "# df_counts = pd.DataFrame(data)\n",
    "# df_counts.head(45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f163b77",
   "metadata": {},
   "source": [
    "## Second iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65652e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DA indicators. Obs: the vars bellow are sensitive to spacing !!! 'hi' != ' hi'\n",
    "\n",
    "# greeting = [' hi','hi.','hello','yo ', 'hey'] \n",
    "# repair_initiator = ['sorry','repeat', 'understand', 'mean ', 'what?', 'example?']\n",
    "# repair = ['I meant']\n",
    "# request_summary = [' correct?','confirm']  \n",
    "# confirmation = ['yes',' correct.',' correct ', 'that\\'s it', 'indeed', 'yeah', 'that\\'s right', 'you got it', 'yep', 'sure', 'okay', 'all right'] \n",
    "# sequence_closer = ['awesome','great','perfect','exactly','that\\'s all','that is all', 'thanks', 'thank you', 'pleasure', 'excellent', 'okay', 'excellent', 'too bad', 'oh well']\n",
    "# inquiry = ['\\?']\n",
    "# receipt = ['You are welcome', 'you\\'re welcome']\n",
    "# disconfirmation = [' no ', 'wrong', 'incorrect', 'not really']\n",
    "\n",
    "# ## !!!!! order-sensitive !!!!\n",
    "\n",
    "# #this variable chooses only one label, rules goes on order. once it assigns one rule it won't check next\n",
    "# temp2=df.new_text.fillna(\"0\")\n",
    "# df['DA_indicators_sent'] =  np.where(temp2.str.contains('|'.join(repair_initiator), case=False), \"repair_initiator\",\n",
    "#                             np.where(temp2.str.contains('|'.join(greeting), case=False), \"greeting\",\n",
    "#                             np.where(temp2.str.contains('|'.join(request_summary), case=False),  \"request_summary\",\n",
    "#                             np.where(temp2.str.contains('|'.join(confirmation), case=False),  \"confirmation\",\n",
    "#                             np.where(temp2.str.contains('|'.join(receipt), case=False),  \"receipt\",\n",
    "#                             np.where(temp2.str.contains('|'.join(disconfirmation), case=False),  \"disconfirmation\",\n",
    "#                             np.where(temp2.str.contains('|'.join(inquiry), case=False),  \"inquiry\",\n",
    "#                             np.where(temp2.str.contains('|'.join(repair), case=False),  \"repair\",\n",
    "#                             np.where(temp2.str.contains('|'.join(sequence_closer), case=False), \"sequence_closer\", \"x\")))))))))\n",
    "\n",
    "# print(df['DA_indicators_sent'].value_counts())\n",
    "\n",
    "# #it works! #binary variables and in the end gather in one new column\n",
    "# ##### ainda n sei se repair solo fica ######                                     \n",
    "                                     \n",
    "# df['DA_rep_init'] =  np.where(temp2.str.contains('|'.join(repair_initiator), case=False), \"repair_initiator\", '')\n",
    "# df['DA_rep'] =  np.where(temp2.str.contains('|'.join(repair), case=False), \"repair\", '')\n",
    "# df['DA_greet'] =  np.where(temp2.str.contains('|'.join(greeting), case=False), \"greeting\", '')\n",
    "# df['DA_req_sum'] =  np.where(temp2.str.contains('|'.join(request_summary), case=False), \"request_summary\", '')\n",
    "# df['DA_conf'] =  np.where(temp2.str.contains('|'.join(confirmation), case=False), \"confirmation\", '')\n",
    "# df['DA_receipt'] =  np.where(temp2.str.contains('|'.join(receipt), case=False), \"receipt\", '')\n",
    "# df['DA_disconf'] =  np.where(temp2.str.contains('|'.join(disconfirmation), case=False), \"disconfirmation\", '')\n",
    "# df['DA_inquiry'] =  np.where(temp2.str.contains('|'.join(inquiry), case=False), \"inquiry\", '')\n",
    "# df['DA_closer'] =  np.where(temp2.str.contains('|'.join(sequence_closer), case=False), \"sequence_closer\", '')\n",
    "# df['all_DA'] = df[['DA_rep_init', 'DA_rep', 'DA_greet','DA_req_sum', 'DA_conf', 'DA_receipt', 'DA_disconf', 'DA_inquiry', 'DA_closer']].agg(' '.join, axis=1)\n",
    "\n",
    "# df['all_DA'] = [word_tokenize(da) for da in df['all_DA']]\n",
    "\n",
    "# df.loc[:, ['speaker', 'new_text', 'all_DA']].to_csv('analysis_multiple_DA_cases_2nditeration.csv')\n",
    "# df.loc[:, ['speaker', 'new_text', 'all_DA']]\n",
    "# counts = df['all_DA'].value_counts()\n",
    "\n",
    "# counts.to_csv('count_overlaping_DAs_2nditeration.csv')\n",
    "# data = {'counts':counts}\n",
    "# df_counts = pd.DataFrame(data)\n",
    "# df_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea1b246",
   "metadata": {},
   "source": [
    "## Third iteration and FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49963883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[grant]</th>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[answer]</th>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[sequence_closer, grant]</th>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[partial_request, grant]</th>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[detail_request, answer]</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          counts\n",
       "[grant]                      367\n",
       "[answer]                     332\n",
       "[sequence_closer, grant]     144\n",
       "[partial_request, grant]     109\n",
       "[detail_request, answer]     104"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DA indicators. Obs: the vars bellow are sensitive to spacing !!! 'hi' != ' hi'\n",
    "\n",
    "greeting = [' hi','hi.','hello','yo ', 'hey', 'How can I help you?'] \n",
    "repair_initiator = ['sorry','repeat', 'understand', 'mean?', 'what?', 'example?', 'could you say that again?', 'say again', 'what did you say?', 'I can\\'t hear you', 'I didn\\'t listen', 'say it again']\n",
    "# repair = ['I meant']\n",
    "request_summary = [' correct?','confirm']  \n",
    "confirmation = ['yes',' correct.',' correct ', 'that\\'s it', 'indeed', 'yeah', 'that\\'s right', 'you got it', 'yep', 'sure', 'okay', 'all right',  'sure', 'sounds good', 'super.', 'super!', 'alright', 'I don\\'t mind', 'I can help you', 'sounds really good', 'got it.'] \n",
    "sequence_closer = ['awesome','great','perfect','exactly','that\\'s all','that is all', 'thanks', 'thank you', 'pleasure', 'excellent', 'okay', 'excellent', 'too bad', 'oh well', 'have a good day', 'enjoy', 'until next time', 'good day', 'good luck', 'bye', 'til next time']\n",
    "receipt = ['You are welcome', 'you\\'re welcome']\n",
    "disconfirmation = [' no ', 'wrong', 'incorrect', 'not really']\n",
    "#NEW\n",
    "completion_check = ['is that all?','anything else I can help you with?', 'anything else?'] \n",
    "partial_request = ['\\?']\n",
    "detail_request = ['\\?']\n",
    "hold_request = ['one moment, please',' hold on', 'hold', 'just a moment', 'let me check for you', 'let me see', 'one sec' ]\n",
    "grant_answer = ['.']\n",
    "temp2=df.new_text.fillna(\"0\")\n",
    "\n",
    "## !!!!! order-sensitive !!!!\n",
    "\n",
    "# #this variable chooses only one label, rules goes on order. once it assigns one rule it won't check next\n",
    "\n",
    "# df['DA_indicators_sent'] =  np.where(temp2.str.contains('|'.join(repair_initiator), case=False), \"repair_initiator\",\n",
    "#                             np.where(temp2.str.contains('|'.join(greeting), case=False), \"greeting\",\n",
    "#                             np.where(temp2.str.contains('|'.join(request_summary), case=False),  \"request_summary\",\n",
    "#                             np.where(temp2.str.contains('|'.join(confirmation), case=False),  \"confirmation\",\n",
    "#                             np.where(temp2.str.contains('|'.join(receipt), case=False),  \"receipt\",\n",
    "#                             np.where(temp2.str.contains('|'.join(disconfirmation), case=False),  \"disconfirmation\",\n",
    "#                             np.where(temp2.str.contains('|'.join(repair), case=False),  \"repair\",\n",
    "#                             np.where(temp2.str.contains('|'.join(sequence_closer), case=False), \"sequence_closer\", \n",
    "#                             np.where(temp2.str.contains('|'.join(completion_check), case=False),  \"completion_check\",\n",
    "#                             np.where(temp2.str.contains('|'.join(hold_request), case=False),  \"hold_request\",\n",
    "#                             np.where(temp2.str.contains('|'.join(partial_request), case=False),  \"partial_request\",\n",
    "#                             np.where(temp2.str.contains('|'.join(detail_request), case=False),  \"detail_request\",\"x\"))))))))))))\n",
    "\n",
    "# print(df['DA_indicators_sent'].value_counts())\n",
    "\n",
    "\n",
    "#it works! #binary variables and in the end gather in one new column\n",
    "##### ainda n sei se repair solo fica ######                                     \n",
    "                                     \n",
    "df['DA_rep_init'] =  np.where(temp2.str.contains('|'.join(repair_initiator), case=False), \"repair_initiator\", '')\n",
    "# df['DA_rep'] =  np.where(temp2.str.contains('|'.join(repair), case=False), \"repair\", '')\n",
    "df['DA_greet'] =  np.where(temp2.str.contains('|'.join(greeting), case=False), \"greeting\", '')\n",
    "df['DA_req_sum'] =  np.where(temp2.str.contains('|'.join(request_summary), case=False), \"request_summary\", '')\n",
    "df['DA_conf'] =  np.where(temp2.str.contains('|'.join(confirmation), case=False), \"confirmation\", '')\n",
    "df['DA_receipt'] =  np.where(temp2.str.contains('|'.join(receipt), case=False), \"receipt\", '')\n",
    "df['DA_disconf'] =  np.where(temp2.str.contains('|'.join(disconfirmation), case=False), \"disconfirmation\", '')\n",
    "df['DA_closer'] =  np.where(temp2.str.contains('|'.join(sequence_closer), case=False), \"sequence_closer\", '')           \n",
    "df['DA_comp_check'] =  np.where(temp2.str.contains('|'.join(completion_check), case=False),  \"completion_check\", '')\n",
    "df['DA_hold'] =  np.where(temp2.str.contains('|'.join(hold_request), case=False),  \"hold_request\", '')\n",
    "df['DA_partial_req'] = np.where(((df['speaker'] == 'USER') & temp2.str.contains('|'.join(partial_request), case=False)), 'partial_request', '')\n",
    "df['DA_detail_req'] = np.where(((df['speaker'] == 'ASSISTANT') & temp2.str.contains('|'.join(detail_request), case=False)), 'detail_request', '')\n",
    "df['DA_grant'] = np.where(((df['speaker'] == 'ASSISTANT') & (temp2.str.contains('|'.join(grant_answer), case=False) & (df['DA_partial_req'].shift(1) == 'partial_request') )), 'grant', '')                                     \n",
    "df['DA_answer'] = np.where(((df['speaker'] == 'USER') & (temp2.str.contains('|'.join(grant_answer), case=False) & (df['DA_detail_req'].shift(1) == 'detail_request') )), 'answer', '')                                     \n",
    "\n",
    "\n",
    "df['all_DA'] = df[['DA_rep_init', 'DA_greet','DA_req_sum', 'DA_conf', 'DA_receipt', 'DA_disconf', 'DA_closer', 'DA_comp_check', 'DA_hold', 'DA_partial_req', 'DA_detail_req', 'DA_grant', 'DA_answer']].agg(' '.join, axis=1)\n",
    "\n",
    "df['all_DA'] = [word_tokenize(da) for da in df['all_DA']]\n",
    "\n",
    "df.loc[:, ['speaker', 'new_text', 'all_DA']].to_csv('analysis_multiple_DA_cases_2nditeration.csv')\n",
    "df.loc[:, ['speaker', 'new_text', 'all_DA']]\n",
    "counts = df['all_DA'].value_counts()\n",
    "\n",
    "counts.to_csv('count_overlaping_DAs_3iteration.csv')\n",
    "data = {'counts':counts}\n",
    "df_counts = pd.DataFrame(data)\n",
    "df_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a2ecae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DA_answer'] = np.where(((df['speaker'] == 'USER') & (temp2.str.contains('|'.join(grant_answer), case=False) & (df['DA_detail_req'].shift(1) == 'detail_request') )), 'answer', '')                                     \n",
    "\n",
    "# df.loc[df['column name'] condition, 'new column name'] = 'value if condition is met'\n",
    "# df.loc[(df['speaker'] != df['speaker'].shift(1)) & (df['DA_indicators_sent'].shift(1) == 'repair_initiator'), 'teste_col2'] = 'SECOND'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d349af72",
   "metadata": {},
   "source": [
    "## Compare binary variable against binary. \n",
    "## Kappa score\n",
    "#### I think it makes no sense to compare the multiple labels together because if only one is different it gives a zero for all\n",
    "\n",
    "The kappa statistic, which is a number between -1 and 1. The maximum value means complete agreement; zero or lower means chance agreement.\n",
    "\n",
    "Conclusion: remove request summary, examples are not matching. Also I don't see any easy to implement rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7dc5e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G_DA_grant\n",
      "DA_grant\n"
     ]
    }
   ],
   "source": [
    "print(df.columns[20])\n",
    "print(df.columns[20+14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93f435c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Cohen's Kappa</th>\n",
       "      <th>Count Gold</th>\n",
       "      <th>Count Synt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>repair_initiator</th>\n",
       "      <td>0.544113</td>\n",
       "      <td>0.854398</td>\n",
       "      <td>0.562575</td>\n",
       "      <td>0.148531</td>\n",
       "      <td>18</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greeting</th>\n",
       "      <td>0.659978</td>\n",
       "      <td>0.929457</td>\n",
       "      <td>0.708778</td>\n",
       "      <td>0.436271</td>\n",
       "      <td>116</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request_summary</th>\n",
       "      <td>0.496111</td>\n",
       "      <td>0.498778</td>\n",
       "      <td>0.497441</td>\n",
       "      <td>-0.003709</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confirmation</th>\n",
       "      <td>0.879387</td>\n",
       "      <td>0.845984</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.721892</td>\n",
       "      <td>515</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>receipt</th>\n",
       "      <td>0.999020</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.956031</td>\n",
       "      <td>0.912070</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disconfirmation</th>\n",
       "      <td>0.569358</td>\n",
       "      <td>0.527592</td>\n",
       "      <td>0.538329</td>\n",
       "      <td>0.078622</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequence_closer</th>\n",
       "      <td>0.678960</td>\n",
       "      <td>0.823679</td>\n",
       "      <td>0.712000</td>\n",
       "      <td>0.438217</td>\n",
       "      <td>226</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>completion_check</th>\n",
       "      <td>0.801643</td>\n",
       "      <td>0.922240</td>\n",
       "      <td>0.851506</td>\n",
       "      <td>0.703147</td>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hold_request</th>\n",
       "      <td>0.965319</td>\n",
       "      <td>0.764651</td>\n",
       "      <td>0.835702</td>\n",
       "      <td>0.672071</td>\n",
       "      <td>66</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial_request</th>\n",
       "      <td>0.924467</td>\n",
       "      <td>0.771037</td>\n",
       "      <td>0.822920</td>\n",
       "      <td>0.649179</td>\n",
       "      <td>329</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detail_request</th>\n",
       "      <td>0.847901</td>\n",
       "      <td>0.942838</td>\n",
       "      <td>0.886875</td>\n",
       "      <td>0.774459</td>\n",
       "      <td>239</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grant</th>\n",
       "      <td>0.728895</td>\n",
       "      <td>0.629716</td>\n",
       "      <td>0.656044</td>\n",
       "      <td>0.321816</td>\n",
       "      <td>338</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer</th>\n",
       "      <td>0.749874</td>\n",
       "      <td>0.807373</td>\n",
       "      <td>0.774055</td>\n",
       "      <td>0.549041</td>\n",
       "      <td>227</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Precision    Recall  F1_macro  Cohen's Kappa  Count Gold  \\\n",
       "repair_initiator   0.544113  0.854398  0.562575       0.148531          18   \n",
       "greeting           0.659978  0.929457  0.708778       0.436271         116   \n",
       "request_summary    0.496111  0.498778  0.497441      -0.003709          16   \n",
       "confirmation       0.879387  0.845984  0.860759       0.721892         515   \n",
       "receipt            0.999020  0.920000  0.956031       0.912070          25   \n",
       "disconfirmation    0.569358  0.527592  0.538329       0.078622          33   \n",
       "sequence_closer    0.678960  0.823679  0.712000       0.438217         226   \n",
       "completion_check   0.801643  0.922240  0.851506       0.703147          27   \n",
       "hold_request       0.965319  0.764651  0.835702       0.672071          66   \n",
       "partial_request    0.924467  0.771037  0.822920       0.649179         329   \n",
       "detail_request     0.847901  0.942838  0.886875       0.774459         239   \n",
       "grant              0.728895  0.629716  0.656044       0.321816         338   \n",
       "answer             0.749874  0.807373  0.774055       0.549041         227   \n",
       "\n",
       "                  Count Synt  \n",
       "repair_initiator         155  \n",
       "greeting                 355  \n",
       "request_summary            5  \n",
       "confirmation             451  \n",
       "receipt                   21  \n",
       "disconfirmation           13  \n",
       "sequence_closer          472  \n",
       "completion_check          38  \n",
       "hold_request              37  \n",
       "partial_request          195  \n",
       "detail_request           318  \n",
       "grant                    175  \n",
       "answer                   289  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.iloc[:,[9,23]]\n",
    "\n",
    "DA = ['repair_initiator','greeting','request_summary','confirmation','receipt','disconfirmation',\n",
    "      'sequence_closer','completion_check','hold_request','partial_request', 'detail_request', 'grant', 'answer'] \n",
    "kappa = []\n",
    "prec_rec_f1 = []\n",
    "count_g = []\n",
    "count_s = []\n",
    "\n",
    "for e,i in enumerate(range(9,22)):\n",
    "    gold = np.asarray([0 if val != DA[e] else 1 for val in df.iloc[:, i]])\n",
    "    synt = np.asarray([0 if val != DA[e] else 1 for val in df.iloc[:, (i+14)]])\n",
    "    kappa.append(sklearn.metrics.cohen_kappa_score(gold, synt))\n",
    "    prec_rec_f1.append(precision_recall_fscore_support(gold, synt, average='macro', zero_division=0))\n",
    "    unique_g, counts_g = np.unique(gold, return_counts=True)\n",
    "    unique_s, counts_s = np.unique(synt, return_counts=True)\n",
    "    count_g.append(counts_g[1])\n",
    "    count_s.append(counts_s[1])\n",
    "\n",
    "# print('kappa: ' + str(np.mean(kappa)))  \n",
    "# kappa_scores = list(zip(DA,kappa))\n",
    "\n",
    "kappa_scores = pd.DataFrame(kappa, index = DA, columns = ['Kappa'])\n",
    "# print(kappa_scores)\n",
    "\n",
    "metrics = pd.DataFrame(prec_rec_f1, index = DA, columns = ['Precision','Recall','F1_macro','Support'])\n",
    "metrics = metrics.drop(columns = 'Support')\n",
    "# metrics = metrics.insert(loc=0,column=count_g, value='Count_Gold')\n",
    "metrics['Cohen\\'s Kappa'] = kappa_scores\n",
    "metrics['Count Gold'] = count_g\n",
    "metrics['Count Synt'] = count_s\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2331b7",
   "metadata": {},
   "source": [
    "## Getting insights from k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dbb51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(df['new_text'])\n",
    "\n",
    "true_k = 5\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "for i in range(true_k):\n",
    "    print('Cluster %d:' % i),\n",
    "    for ind in order_centroids[i, :5]:\n",
    "        print(' %s' % terms[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df3fdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Prediction')\n",
    "X = vectorizer.transform(['hi, can you help me?'])\n",
    "predicted = model.predict(X)\n",
    "print(predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
