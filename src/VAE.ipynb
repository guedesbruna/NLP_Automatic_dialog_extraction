{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46aea06d",
   "metadata": {},
   "source": [
    "From paper:\n",
    "https://github.com/maitreyeeT/Seq2SeqDialStruct/blob/431419204a4156d633d0d744657fc0cbeef08ce6/Seq2SeqVAE_dialogueStructuring/vae_LSTM.py#L39\n",
    "\n",
    "Look for tutorials on VAE. preferably pytorch? (or not, i don't think i used it yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ec972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "# from Seq2SeqVAE_dialogueStructuring.variational_layer import VariationalLayer\n",
    "l = keras.layers\n",
    "m = keras.models\n",
    "K = keras.backend\n",
    "opt = keras.optimizers\n",
    "losses = keras.losses\n",
    "cbk = keras.callbacks\n",
    "reg = keras.regularizers\n",
    "\n",
    "\n",
    "class LSTMVAutoencoder:\n",
    "\n",
    "    def __init__(self, lr, window_size, sequence_size, dropout=0.):\n",
    "        self.lr = lr\n",
    "        self.window_size = window_size\n",
    "        self.sequences_length = sequence_size\n",
    "       # self.input_convolution_size = 3\n",
    "       # self.conv_2d_filters = []  # Num filter of the convolution layers\n",
    "       # self.conv_2d_kernels = []  # Kernel sizes of the convolution layers\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.regul = 1e-4\n",
    "        self.latent_dim = 256\n",
    "        self.build()\n",
    "\n",
    "    def get_attention(self,name, output_size, dropout=0., axis=-2):\n",
    "        model_att = m.Sequential(name='attention_' + str(name))  # (?, n, k, x)\n",
    "        model_att.add(l.Dense(1, activation=K.exp))  # (?, n, k, 1)\n",
    "        model_att.add(l.Lambda(lambda x: x / (K.sum(x, axis=axis, keepdims=True) + \\\n",
    "                                              K.epsilon()),\n",
    "                               name=name + 'attention'))  # (?, n, k, 1)\n",
    "\n",
    "        m_att = m.Sequential()\n",
    "        m_att.add(l.Lambda(lambda x: K.sum(x * model_att(x), axis=axis)))\n",
    "        m_att.add(l.Dense(output_size, activation='linear'))\n",
    "        return m_att\n",
    "\n",
    "    def make_networks(self):\n",
    "        attention = self.get_attention('xylo',10)\n",
    "        #from w2vec_utils import train_word2vec, data_transform\n",
    "        #data_embed = data_transform()\n",
    "        #w2vmodel, embed_wts = train_word2vec(data_embed)\n",
    "        encoder = m.Sequential(name='encoder')\n",
    "        #encoder.add(l.Embedding(output_dim=300, weights=[embed_wts],input_dim=embed_wts.shape[0],\n",
    "        #                        input_shape=(self.sequences_length,2)))\n",
    "        #encoder.add(l.Lambda(lambda x: K.mean(x, axis=-2)))\n",
    "        encoder.add(l.LSTM(10, return_sequences='True'))\n",
    "        encoder.add(l.LSTM(10, return_sequences='True'))\n",
    "\n",
    "        encoder.add(attention)\n",
    "        #encoder.add(l.Dense(5, activity_regularizer=reg.l2(1e-3)))\n",
    "\n",
    "        self.encoder = encoder\n",
    "\n",
    "        decoder = m.Sequential(name='decoder')\n",
    "        decoder.add(l.RepeatVector(self.sequences_length))\n",
    "        decoder.add(l.LSTM(10, return_sequences=True))\n",
    "        decoder.add(l.LSTM(self.window_size, activation='sigmoid'\n",
    "                           , return_sequences=True))\n",
    "\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def build(self):\n",
    "\n",
    "        seq_input = l.Input(shape=(self.sequences_length, self.window_size),\n",
    "                            dtype='float32')  # (?, n, k)\n",
    "\n",
    "        self.make_networks()\n",
    "\n",
    "        latent_in = self.encoder(seq_input)\n",
    "    #     latent_in = VariationalLayer(10, kl_gain=1e-3)(latent_in) <<<< variational layer. commented since i don't yet hve the code for this\n",
    "\n",
    "        decoder_out = self.decoder(latent_in)\n",
    "\n",
    "        model = m.Model(inputs=[seq_input], outputs=[decoder_out])\n",
    "\n",
    "        model_latent = m.Model(inputs=[seq_input], outputs=[latent_in])\n",
    "\n",
    "        model.compile(opt.Adam(self.lr), loss=[lambda x, y: losses.binary_crossentropy(x, y)])\n",
    "\n",
    "        model_latent.compile(opt.RMSprop(1e-3), loss='binary_crossentropy')\n",
    "        self.model = model\n",
    "        self.model_latent = model_latent\n",
    "\n",
    "    def fit(self, X, epochs, callbacks=None, verbose=2):\n",
    "\n",
    "        self.model.fit(x=[X],\n",
    "                       y=[X],\n",
    "                       batch_size=30,\n",
    "                       epochs=epochs,\n",
    "                       validation_split=.2,\n",
    "                       callbacks=callbacks,\n",
    "                       verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374550eb",
   "metadata": {},
   "source": [
    "## LSTM Autoencoders\n",
    "\n",
    "https://machinelearningmastery.com/lstm-autoencoders/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9068756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85effc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 10:42:52.024640: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-02 10:42:52.745231: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10486767 0.19934608 0.29777828 0.39852583 0.50044525 0.6015635\n",
      " 0.7009781  0.7998287  0.89919174]\n"
     ]
    }
   ],
   "source": [
    "# For these demonstrations, we will use a dataset of one sample of nine time steps and one feature:\n",
    "# [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# We can start-off by defining the sequence and reshaping it into the preferred shape of [samples, timesteps, features].\n",
    "\n",
    "# define input sequence\n",
    "sequence = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "# reshape input into [samples, timesteps, features]\n",
    "n_in = len(sequence)\n",
    "sequence = sequence.reshape((1, n_in, 1))\n",
    "\n",
    "# Next, we can define the encoder-decoder LSTM architecture that expects input sequences with nine time steps\n",
    "#and one feature and outputs a sequence with nine time steps and one feature.\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_in,1)))\n",
    "model.add(RepeatVector(n_in))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Next, we can fit the model on our contrived dataset.\n",
    "\n",
    "# fit model\n",
    "model.fit(sequence, sequence, epochs=300, verbose=0)\n",
    "# plot_model(model, show_shapes=True, to_file='reconstruct_lstm_autoencoder.png')\n",
    "# demonstrate recreation\n",
    "yhat = model.predict(sequence, verbose=0)\n",
    "print(yhat[0,:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71da3530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16533749 0.2886588  0.40279546 0.50950813 0.6105695  0.7070858\n",
      " 0.7999728  0.89002454]\n"
     ]
    }
   ],
   "source": [
    "# define input sequence\n",
    "seq_in = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "# reshape input into [samples, timesteps, features]\n",
    "n_in = len(seq_in)\n",
    "seq_in = seq_in.reshape((1, n_in, 1))\n",
    "# prepare output sequence\n",
    "seq_out = seq_in[:, 1:, :]\n",
    "n_out = n_in - 1\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_in,1)))\n",
    "model.add(RepeatVector(n_out))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# plot_model(model, show_shapes=True, to_file='predict_lstm_autoencoder.png')\n",
    "\n",
    "# fit model\n",
    "model.fit(seq_in, seq_out, epochs=300, verbose=0)\n",
    "# demonstrate prediction\n",
    "yhat = model.predict(seq_in, verbose=0)\n",
    "print(yhat[0,:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7cda888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # lstm autoencoder reconstruct and predict sequence\n",
    "# from numpy import array\n",
    "# import keras\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import RepeatVector\n",
    "# from keras.layers import TimeDistributed\n",
    "\n",
    "# m = keras.models\n",
    "# l = keras.layers\n",
    "# # Finally, we can create a composite LSTM Autoencoder that has a single encoder and two decoders,\n",
    "# # one for reconstruction and one for prediction.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # define model\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(100, activation='relu', input_shape=(n_in,1)))\n",
    "# model.add(RepeatVector(n_out))\n",
    "# model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "# model.add(TimeDistributed(Dense(1)))\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "# # plot_model(model, show_shapes=True, to_file='predict_lstm_autoencoder.png')\n",
    "\n",
    "\n",
    "# ##########\n",
    "\n",
    "# # define input sequence\n",
    "# seq_in = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "# # reshape input into [samples, timesteps, features]\n",
    "# n_in = len(seq_in)\n",
    "# seq_in = seq_in.reshape((1, n_in, 1))\n",
    "# # prepare output sequence\n",
    "# seq_out = seq_in[:, 1:, :]\n",
    "# n_out = n_in - 1\n",
    "\n",
    "# # define encoder\n",
    "# visible = Input(shape=(n_in,1))\n",
    "# encoder = LSTM(100, activation='relu')(visible)\n",
    "# print(encoder)\n",
    "\n",
    "# # define reconstruct decoder\n",
    "# decoder1 = RepeatVector(n_in)(encoder)\n",
    "# # decoder1_l1 = LSTM(100, activation='relu', return_sequences=True)(decoder1)\n",
    "# # decoder1_l2 = LSTM(100, activation='relu', return_sequences=True)(decoder1_l1)\n",
    "# # decoder1_o = TimeDistributed(Dense(1))(decoder1_l2) #layer wrapper\n",
    "# decoder1 = LSTM(100, activation='relu', return_sequences=True)(decoder1)\n",
    "# decoder1 = TimeDistributed(Dense(1))(decoder1) #layer wrapper\n",
    "# print('decoder1: '+ str(decoder1))\n",
    "# print('\\n')\n",
    "\n",
    "# # define predict decoder\n",
    "# decoder2 = RepeatVector(n_out)(encoder)\n",
    "# decoder2_l1 = LSTM(100, activation='relu', return_sequences=True)(decoder2)\n",
    "# decoder2_l2 = LSTM(100, activation='relu', return_sequences=True)(decoder2_l1)\n",
    "# decoder2_o = TimeDistributed(Dense(1))(decoder2_l2) #layer wrapper\n",
    "# print('decoder2: '+ str(decoder2_o))\n",
    "# print('\\n')\n",
    "\n",
    "# # tie it together\n",
    "# model = Model(inputs=visible, outputs=[decoder1, decoder2])\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# # fit model\n",
    "# model.fit(seq_in, [seq_in,seq_out], epochs=300, verbose=0)\n",
    "\n",
    "# # demonstrate prediction\n",
    "# yhat = model.predict(seq_in, verbose=0)\n",
    "# print('yhat: ' + str(yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2e7fcbf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3s/9v17gzrj1kvctdbg2vd9d2qw0000gn/T/ipykernel_23854/2259882938.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0madd_special_tok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/NLP_Automatic_dialog_extraction/./src/ngrams.py\u001b[0m in \u001b[0;36madd_special_tok\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdialog\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mdialog_DA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conversation_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdialog\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mdialog_DA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'all_DA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__eq__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__ne__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5501\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5502\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5504\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/inteamenv/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from src/ngrams import add_special_tok\n",
    "import pandas as pd\n",
    "import sys\n",
    "from ngrams import add_special_tok\n",
    "\n",
    "df = pd.read_csv('./data_TM2/processed/processed_utterances_sentence_DA_labeling.csv', index_col=0)\n",
    "df.head()\n",
    "\n",
    "add_special_tok(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c1cd523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[0.11162275],\n",
      "        [0.20765445],\n",
      "        [0.30347523],\n",
      "        [0.39957055],\n",
      "        [0.49649748],\n",
      "        [0.59487337],\n",
      "        [0.6952509 ],\n",
      "        [0.79859203],\n",
      "        [0.9059592 ]]], dtype=float32), array([[[0.16432385],\n",
      "        [0.28716987],\n",
      "        [0.40201792],\n",
      "        [0.50994134],\n",
      "        [0.61183226],\n",
      "        [0.7084466 ],\n",
      "        [0.80043477],\n",
      "        [0.888363  ]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# lstm autoencoder reconstruct and predict sequence\n",
    "from numpy import array\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "# define input sequence\n",
    "seq_in = array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9])\n",
    "# reshape input into [samples, timesteps, features]\n",
    "n_in = len(seq_in)\n",
    "seq_in = seq_in.reshape((1, n_in, 1))\n",
    "# prepare output sequence\n",
    "seq_out = seq_in[:, 1:, :]\n",
    "n_out = n_in - 1\n",
    "\n",
    "# define encoder\n",
    "visible = Input(shape=(n_in,1))\n",
    "encoder = LSTM(100, activation='relu')(visible)\n",
    "\n",
    "# define reconstruct decoder\n",
    "decoder1 = RepeatVector(n_in)(encoder)\n",
    "decoder1 = LSTM(100, activation='relu', return_sequences=True)(decoder1)\n",
    "decoder1 = TimeDistributed(Dense(1))(decoder1)\n",
    "\n",
    "# define predict decoder\n",
    "decoder2 = RepeatVector(n_out)(encoder)\n",
    "decoder2 = LSTM(100, activation='relu', return_sequences=True)(decoder2)\n",
    "decoder2 = TimeDistributed(Dense(1))(decoder2)\n",
    "\n",
    "# tie it together\n",
    "model = Model(inputs=visible, outputs=[decoder1, decoder2])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(seq_in, [seq_in,seq_out], epochs=300, verbose=0)\n",
    "\n",
    "# demonstrate prediction\n",
    "yhat = model.predict(seq_in, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4301f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
